---
tags:
  - 논문
link: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE10659470
category: Machine Learning
author: 신승수, 조동희, 김용혁
journal: 한국융합학회
math_level: "3.5"
---
## 1. 논문의 핵심 요약
---
많은 게임들이 사용자의 게임 리플레이나 그와 관련한 데이터를 제공하고 있고, 이 데이터에 기계학습 기법을 결합해 상대의 행동을 예측하기 위한 연구들이 진행되고 있다. 이 연구에서는 Supercell 게임사의 Clash Royale에 대한 연구 결과, 가장 개선을 보인 전처리 방식은 중첩 형태의 데이터를 초반으로 분할했을 경우로, 카드 타입이 약 2.6%, 카드 배치 좌표가 약 1.8% 개선된 것을 볼 수 있었다. 


## 2. 연구 목적
---
과거와는 다르게, 클래시 로얄이나 클래시 오브 클랜 등의 특정 게임에서는 사용자의 게임 플레이를 리플레이 형식으로 제공하고 있다. 이에 맞춰, 최근의 게임 산업에서는 관련 데이터와 기계학습 기법을 결합한 다양한 연구들이 진행되고 있는데, 특히 **강화학습 기법과 게임 내적인 요소들을 예측하는 연구**는 말 그대로 예측이기 때문에 게임의 결과에 있어 매우 중요하기도 하며 AI 대전 등 유저와 직접 게임을 진행할 수도 있어 매우 중요하다. 

게임 내 행동 예측의 경우, 실시간 전략 게임에서는 **자원, 유닛, 맵, 제한시간** 등의 다양한 변수가 존재한다. 따라서 상대방의 행동 예측을 위해 고려해야 할 경우의 수가 무한하다는 특징이 있다. 이번 연구에서 다루는 클래시 로얄은 알다시피 카드 기반 실시간 전략 게임으로, 두 명 또는 네 명의 사용자가 지도에 카드를 배치해 서로의 타워를 깨는 것을 목표로 한다. 

클래시 로얄은 기존 실시간 전략게임과 달리, 상대적으로 좁은 크기의 맵과 3분이라는 제한된 경기 시간이 있어 행동 예측에 비교적 적합하며 유명해서 데이터가 쌓이기 유리하다.

## 3. 문제 정의
---
이번 연구에서는 클래시 로얄의 경기 기록 데이터와 기계학습 기반의 [[다중 레이블 분류]]룰 사용해 상대 플레이어의 행동을 예측하고 이를 비교한다.

## 4. 핵심 아이디어
---
예측을 위한 기계학습 기법으로는 [[랜덤 포레스트]]와 [[다중 퍼셉트론]]이 사용되었다. 이 과정에서, 초기 데이터를 개선시킨 3가지 전처리 방식을 순차적으로 설명하고 실험한다.

## 5. 방법론
---
논문에서는 기본적으로 두 가지의 알고리즘을 사용했다.

**1. 랜덤 포레스트**
- 앙상블 기법 기반의 결정 트리(Decision Tree) 모델로, 여러개의 결정 트리를 학습시켜 다수결로 최종 예측을 도출한다. 
- 각 데이터 포인트에 대해서 다양한 트리를 구성해 다중 레이블 예측에서 강건하다.

**2. 다층 퍼셉트론**
- 입력층 - 은닉층 - 출력층 구조의 기본적인 인공신경망 모델이다. 
- 비선형적인 특성을 학습할 수 있어, 카드 배치 전략 등의 복잡한 행동 패턴을 연구하는 데 쓰임

클래시 로얄에서 플레이어는 한 번에 여러 개의 카드 선택과 배치를 할 수 있어 하나의 입력에 대해 여러 개의 출력(레이블)을 예측해야 하는 문제가 생긴다. (예: 미니 페카를 막기 위해 배치해야 하는 유닛 또는 건물 또는 마법)

따라서, 다중 레이블 분류는 각각의 입력 샘플이 여러 개의 출력을 동시에 가질 수 있기 때문에 다중 레이블 분류로 접근이 필요했다. 


## 6. 실험 or 연구 및 결과
---
먼저, 데이터셋은 다음의 방식으로 추출했다.

**1. 클래시로얄 응용 프로그램 인터페이스 사용**
- 2020.03.20 ~ 2020.04.13 기간에 해당하는 상위 100명의 플레이어 전적 기록 100000개 추출
- 전적 기록 검색 기능을 통해 카드 배치 정보를 담고 있는 경기 데이터 추출
- 양 플레이어가 사용한 카드의 합이 40회 이상인 게임을 정상으로 판단해 49633개 데이터 추출

**2. Deckshop에서 클래시로얄의 모든 카드에 대한 특성/수치 정보 크롤링**
- 위에서 추출한 경기 데이터를 전처리하기 위해 수집
- 다음 사진과 같이 표현 가능함
	![[Pasted image 20260211235658.png]]

또한, 단순 모델만 적용한 것이 아니라, 순차적으로 3가지 데이터 전처리 방식을 사용했다. 

**1. 초기 방식**
- 입력 데이터는 **카드의 특성, 카드 배치 좌표, 시간 정보**의 3가지로 구성
	- 카드 특성은 총 45가지로 해당 카드의 특성 보유 여부에 따라 이진 다중 레이블로 표현
	- 카드 배치 좌표는 맵에서 상하, 좌우, 진영에서의 상하, 다리 근방의 유무 4가지로 이진 다중 레이블로 표현
	- 시간 정보는 카드를 내는 순서를 정규화시킨 값으로, 카드 특성에서의 카드 타입 데이터와 카드 배치 좌표를 이진 다중 레이블로 구성
- 해당 방식의 실험 데이터는 다음과 같이 구성됨
	![[Pasted image 20260212000441.png]]

**2. 특성 정보 변환**
- 카드 특성 정보 중 19개를 실수형 수치 정보가 담긴 12개의 레이블로 변환시키고 이것을 "Card Ability"라고 지정
- 이 과정에서 사용되는 수치 정보는 Deckshop에서 크롤링한 수치 정보 사용
- 해당 방식의 실험 데이터는 다음과 같이 구성됨
	![[Pasted image 20260212000640.png]]

**3. 중첩 입력 방식**
- 클래시 로얄 게임 특성상 카드가 연속적일 수 있다는 것을 고려한 것
- 기존의 1대 1 카드 대응 방식과 더불어 연속된 카드 입력 방식인 N대 1 방식을 고려해 입력 데이터를 중첩해 구성
- 해당 방식의 실험 데이터는 다음과 같이 구성됨
	![[Pasted image 20260212000840.png]]

**4. 시간 기준에 따른 분할**
- 이전 단계의 모든 데이터들은 시간 정보 값 0.5를 기준으로 초반과 후반으로 나뉨
- 프린세스 타워 하나가 무너졌을 때 카드를 낼 수 있는 좌표 범위가 증가하며, 게임의 잔여 시간이 1분 미만이 될 때 & 타이브레이커 이전에 각각 카드 배치 비용이 2배 & 3배로 단축
- 이 점을 고려해 경기의 초반, 후반에 플레이어의 카드 배치가 달라질 것으로 생각함

아래의 그림은 1부터 4까지에 해당하는 순차적인 전처리 방식의 순서도로, 이 과정에서 각 단계마다 생성된 데이터를 알파벳에 해당하는 시나리오로 치환할 수 있음

![[Pasted image 20260212001238.png]]

실제 실험에서는 9가지의 데이터 시나리오를 사용해 각 데이터 시나리오마다 1000000개 이상의 데이터가 존재하여 최대한 많은 데이터를 학습에 사용하기 위해 Train Set과 Test Set을 9:1 비율로 나누어 사용했다. 

랜덤포레스트에서는 의사결정트리의 개수를 100개로 설정했으며, 각 의사결정트리의 노드 분할 기준은 트리의 유사성을 피하기 위해 [[지니계수|지니 계수]]를 사용했다. 

다층 퍼셉트론에서는 100개의 노드로 구성된 1개의 은닉층을 가지고 있으며, 활성화 함수로는 정류된 선형 유닛(ReLu)을 사용했다. 출력층은 이진 형태의 값을 반환하며 카드 타입, 카드 배치 정보에 대해 각각 3, 4개의 노드로 구성된다. 손실 값 최적화를 위해 아담(Adam)함수를 사용했으며, 에포크 수는 20, 배치 크기는 200이다. 

**실험 결과는 다음 표와 같다.**
![[Pasted image 20260212004119.png]]

간단하게 요약하면, 기계학습 기법을 사용했을 때 정확도와 F1 점수는 다층 퍼셉트론을 사용했을 때가 높았지만, 학습세트의 정확도와 F1 점수는 랜덤 포레스트가 더 높았다. 

가장 높은 성능 개선을 보인 조합은 **중첩 입력 형태의 데이터를 시간에 따라 초반으로 분할한 H 데이터와 다층 퍼셉트론에 적용한 경우**이며, 이때는 카드 타입이 약 2.6%, 카드 배치 좌표가 약 1.8% 개선되었다. 

## 7. 결론 및 한계
---
이 논문에서는 순차적인 3가지 전처리 방식을 제안하고 이들의 성능을 서로 비교했으며, 그 결과 3가지 전처리 방식 중 마지막 단계에서 중첩 입력 형태의 데이터를 시간에 따라 초반으로 분할한 경우 가장 높은 성능 개선을 보였다. 따라서, 상대방의 행동 예측에 대해 게임의 시점이 영향을 끼치는 요소라는 것을 알 수 있었다. 

그러나, 이 연구에서 사용된 경기 데이터는 경기에서의 유닛 및 마법 배치 정보만을 알 수 있었으며, 해당 배치 시점에서의 게임의 전반적인 상황은 반영하지 않았다는 한계점이 있었다. 따라서, 경기의 배치 기록이 아닌 경기 리플레이 데이터를 사용한다면, 추후 연구에서는 기존의 행동 예측 연구처럼 높은 성능의 행동 예측 연구가 가능할 것이다.

또한, 양 플레이어가 사용한 카드의 합이 40개 이상인 경우의 데이터를 사용했는데, 사용한 카드 중 대부분이 스펠 난사 등의 무의미한 경우였을 때는 어떻게 대처했는지 궁금했다.

## 8. 더 공부할 내용
---
대부분의 내용이 머신 러닝과 관련된 내용이다 보니, 3학년 2학기 때 배웠던 AI 보안 과목을 다시 한 번 제대로 복습해보는 것이 필요할 것 같다. 

## 9. 비슷한 논문 / 선행 or 후속 연구
---
- D. Silver et al. (2016). Mastering the game of Go with deep neural networks and tree search. Nature, 529, 484-489.
	- 심층 신경망과 몬테 카를로 트리 탐색을 이용해 바둑 경기에 최적화된 모델 성능 향상
- A. Dockhorn, M. Frick, Ü. Akkaya & R. Kruse. (2018, May). Predicting opponent moves for improving hearthstone AI. Information Processing and Management of Uncertainty in Knowledge-based Systems. Theory and Foundations (pp. 621-632).
	- 하스스톤에서 상황에 대해 점수를 부여하는 방식 + 몬테 카를로 트리 탐색으로 역전파를 통해 가장 높은 점수가 나오는 상대방의 카드를 평가 및 예측
- 백인성, 강현구, 조윤상, 이영재, 박영준, 조억, and 김성범, "3차원 합성곱 신경망을 활용한 실시간 전략 게임 승패 예측," 대한산업공학회지, vol. 46, no. 4, pp. 349-355, 2020.
	- 스타크래프트2 리플레이 데이터를 기반으로 시점별 리플레이 이미지가 가지는 공간 정보를 사용해 승패를 예측할 수 있는 3차원 합성곱 신경망 모델을 제안