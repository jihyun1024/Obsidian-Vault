---
tags:
  - 논문
link: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE10659470
category: Machine Learning
author: 신승수, 조동희, 김용혁
journal: 한국융합학회
math_level: "3.5"
---
## 1. 논문의 핵심 요약
---
많은 게임들이 사용자의 게임 리플레이나 그와 관련한 데이터를 제공하고 있고, 이 데이터에 기계학습 기법을 결합해 상대의 행동을 예측하기 위한 연구들이 진행되고 있다. 이 연구에서는 Supercell 게임사의 Clash Royale에 대한 연구 결과, 가장 개선을 보인 전처리 방식은 중첩 형태의 데이터를 초반으로 분할했을 경우로, 카드 타입이 약 2.6%, 카드 배치 좌표가 약 1.8% 개선된 것을 볼 수 있었다. 


## 2. 연구 목적
---
과거와는 다르게, 클래시 로얄이나 클래시 오브 클랜 등의 특정 게임에서는 사용자의 게임 플레이를 리플레이 형식으로 제공하고 있다. 이에 맞춰, 최근의 게임 산업에서는 관련 데이터와 기계학습 기법을 결합한 다양한 연구들이 진행되고 있는데, 특히 **강화학습 기법과 게임 내적인 요소들을 예측하는 연구**는 말 그대로 예측이기 때문에 게임의 결과에 있어 매우 중요하기도 하며 AI 대전 등 유저와 직접 게임을 진행할 수도 있어 매우 중요하다. 

게임 내 행동 예측의 경우, 실시간 전략 게임에서는 **자원, 유닛, 맵, 제한시간** 등의 다양한 변수가 존재한다. 따라서 상대방의 행동 예측을 위해 고려해야 할 경우의 수가 무한하다는 특징이 있다. 이번 연구에서 다루는 클래시 로얄은 알다시피 카드 기반 실시간 전략 게임으로, 두 명 또는 네 명의 사용자가 지도에 카드를 배치해 서로의 타워를 깨는 것을 목표로 한다. 

클래시 로얄은 기존 실시간 전략게임과 달리, 상대적으로 좁은 크기의 맵과 3분이라는 제한된 경기 시간이 있어 행동 예측에 비교적 적합하며 유명해서 데이터가 쌓이기 유리하다.

## 3. 문제 정의
---
이번 연구에서는 클래시 로얄의 경기 기록 데이터와 기계학습 기반의 [[다중 레이블 분류]]룰 사용해 상대 플레이어의 행동을 예측하고 이를 비교한다.

## 4. 핵심 아이디어
---
예측을 위한 기계학습 기법으로는 [[랜덤 포레스트]]와 [[다중 퍼셉트론]]이 사용되었다. 이 과정에서, 초기 데이터를 개선시킨 3가지 전처리 방식을 순차적으로 설명하고 실험한다.

## 5. 방법론
---
논문에서는 기본적으로 두 가지의 알고리즘을 사용했다.

**1. 랜덤 포레스트**
- 앙상블 기법 기반의 결정 트리(Decision Tree) 모델로, 여러개의 결정 트리를 학습시켜 다수결로 최종 예측을 도출한다. 
- 각 데이터 포인트에 대해서 다양한 트리를 구성해 다중 레이블 예측에서 강건하다.

**2. 다층 퍼셉트론**
- 입력층 - 은닉층 - 출력층 구조의 기본적인 인공신경망 모델이다. 
- 비선형적인 특성을 학습할 수 있어, 카드 배치 전략 등의 복잡한 행동 패턴을 연구하는 데 쓰임

클래시 로얄에서 플레이어는 한 번에 여러 개의 카드 선택과 배치를 할 수 있어 하나의 입력에 대해 여러 개의 출력(레이블)을 예측해야 하는 문제가 생긴다. (예: 미니 페카를 막기 위해 배치해야 하는 유닛 또는 건물 또는 마법)

따라서, 다중 레이블 분류는 각각의 입력 샘플이 여러 개의 출력을 동시에 가질 수 있기 때문에 다중 레이블 분류로 접근이 필요했다. 


## 6. 실험 or 연구 및 결과
---
(데이터셋, 실험 설정 또는 연구 과정, 주요 결과 요약, 한계를 드러낸 실험 또는 인상 깊은 figure)
먼저, 데이터셋은 다음의 방식으로 추출했다.


## 7. 결론 및 한계
---
이 논문에서는 순차적인 3가지 전처리 방식을 제안하고 이들의 성능을 서로 비교했으며, 그 결과 3가지 전처리 방식 중 마지막 단계에서 중첩 입력 형태의 데이터를 시간에 따라 초반으로 분할한 경우 가장 높은 성능 개선을 보였다. 따라서, 상대방의 행동 예측에 대해 게임의 시점이 영향을 끼치는 요소라는 것을 알 수 있었다. 

그러나, 이 연구에서 사용된 경기 데이터는 경기에서의 유닛 및 마법 배치 정보만을 알 수 있었으며, 해당 배치 시점에서의 게임의 전반적인 상황은 반영하지 않았다는 한계점이 있었다. 따라서, 경기의 배치 기록이 아닌 경기 리플레이 데이터를 사용한다면, 추후 연구에서는 기존의 행동 예측 연구처럼 높은 성능의 행동 예측 연구가 가능할 것이다.

## 8. 더 공부할 내용
---
대부분의 내용이 머신 러닝과 관련된 내용이다 보니, 3학년 2학기 때 배웠던 AI 보안 과목을 다시 한 번 제대로 복습해보는 것이 필요할 것 같다. 

## 9. 비슷한 논문 / 선행 or 후속 연구
---
- D. Silver et al. (2016). Mastering the game of Go with deep neural networks and tree search. Nature, 529, 484-489.
	- 심층 신경망과 몬테 카를로 트리 탐색을 이용해 바둑 경기에 최적화된 모델 성능 향상
- A. Dockhorn, M. Frick, Ü. Akkaya & R. Kruse. (2018, May). Predicting opponent moves for improving hearthstone AI. Information Processing and Management of Uncertainty in Knowledge-based Systems. Theory and Foundations (pp. 621-632).
	- 하스스톤에서 상황에 대해 점수를 부여하는 방식 + 몬테 카를로 트리 탐색으로 역전파를 통해 가장 높은 점수가 나오는 상대방의 카드를 평가 및 예측
- 백인성, 강현구, 조윤상, 이영재, 박영준, 조억, and 김성범, "3차원 합성곱 신경망을 활용한 실시간 전략 게임 승패 예측," 대한산업공학회지, vol. 46, no. 4, pp. 349-355, 2020.
	- 스타크래프트2 리플레이 데이터를 기반으로 시점별 리플레이 이미지가 가지는 공간 정보를 사용해 승패를 예측할 수 있는 3차원 합성곱 신경망 모델을 제안