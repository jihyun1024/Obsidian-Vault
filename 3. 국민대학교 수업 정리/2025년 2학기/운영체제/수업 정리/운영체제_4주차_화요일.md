---
tags:
  - 3학년_2학기
---
## 학습 주제
1. Thread
2. Multicore Programming
3. Concurrency vs. Parallelism

---
## 연관 수업
[[운영체제_3주차_목요일]]

---
## 강의 요약
이번 수업부터 다음주 화요일 수업까지는 Process 내부의 단위인 Thread에 대해 다룬다. 
### Thread
여태껏 우리는 Process에 대해 공부했다. Process는 실행 중인 프로그램으로, 프로그램과의 차이는 그 프로그램이 하드디스크에 저장만 되었는지(프로그램), 그 프로그램이 실제로 수행되어 메모리에 올라가 CPU가 작업을 수행 중인 상태인지(Process)에 따라 갈린다. 

그렇다면, [[운영체제_2주차_목요일#Thread|Thread]]를 미리 개괄했던 내용에서 보듯, Thread는 무엇일까?
Thread는 하나의 프로세스(프로그램) 안에서 실행되는 **작업의 흐름 단위**로, 프로그램이 어떤 일을 할 때, 그 일을 세분화해서 동시에 여러 작업을 처리할 수 있도록 한다. 

예를 들어, I/O 작업을 수행하며 Obsidian 문서를 편집하며 동시에 YouTube 동영상을 볼 때, 이 중 하나의 작업이라도 멈추면 안 되기 때문에 동시성을 위해 사용하는 경우가 있다. 

**이 때 각각의 작업이 Thread로 나뉘어 동시에 실행된다.** 

이 때, Process는 실행 중인 프로그램 하나를 의미하며, 독립된 메모리 공간을 갖지만, Thread는 하나의 Process 내에서 실행 중인 작업의 단위이기 때문에 여러 Thread는 같은 자원(코드, 데이터, 파일 등)을 공유한다. 이를 그림으로 표현할 수도 있다. ![[Pasted image 20251001000851.png]]

Multithreaded Programming의 장점은 여러 가지가 있다. 
1. Responsiveness(응답성): UI Thread와 작업 Thread를 분리해 작업은 백그라운드에서 처리하고, UI Thread는 사용자 입력에 계속 반응해 사용자의 입력에 빠르게 반응할 수 있다. 
2. Resource Sharing(자원 공유): 여러 Thread는 같은 자원을 공유하기 때문에 Process에서의 [[운영체제_3주차_목요일#Shared Memory|shared memory]]나 [[운영체제_3주차_목요일#Message Passing|message passing]]보다 더 간단하다. 
3. Economy(경제적): Process를 새로 만드는 것보다 더 간단하며, thread switching 또한 Process의 Context Switching보다 더 낮은 오버헤드를 가진다. 
4. Scalablity(병렬성): Thread의 사용은 Multicore Programming에 적합하다. 

### Multicore Programming
아빠와 함께 다나와에서 컴퓨터 견적을 보다 보면 이런 사진을 종종 볼 수 있다. 
![[Pasted image 20251001005702.png]]
여기서 '몇 코어, 몇 스레드'라는 표현을 볼 수 있는데, 이게 뭘까? 

정답은 CPU 내에 ALU, 제어장치, 레지스터 등으로 이루어진 코어가 몇 개 있는지를 나타낸 것이다. 전통적인 CPU, 즉 교과서적인 CPU는 ALU, 제어장치, 레지스터 등으로 이루어지며, 이게 단 하나만 존재하는 싱글 코어이지만, 현재 우리가 이 문서를 편집하며 사용하는 컴퓨터의 CPU는 여러 개의 코어가 CPU를 이루며, 그 말인 즉슨 여러 개의 Thread를 동시에 수행할 수 있다는 의미이다. 

이를 Multicore Processor라고 한다. 몇 개의 코어가 있는지에 따라 쿼드코어, 헥사코어, 옥타코어 등으로 나누어지는 것을 볼 수 있다. 

*예시로, 지금 내 컴퓨터인 갤럭시북 5 프로에는 Intel Core Ultra 7 258V 프로세서가 설치되어 있으며, 이 프로세서는 P-코어(고성능 코어) 4개와 E-코어(고효율 코어) 4개 총 8개의 코어를 사용하며 8 스레드를 사용하여 이론적으로 최대 8개의 작업을 동시에 수행할 수 있다.* 

이처럼, Multithreading은 멀티코어 시스템에서 사용되며, 병렬성과 동시성을 향상시킬 수 있다. (그 둘의 차이는 이따가 알아보자.)

사실, 멀티코어 프로그래밍은 아래 ~~귀여운~~ 사진처럼 굉장히 구현하기 어려운 개념이다. 
![[Pasted image 20251001011352.png]]
대표적으로, 다음과 같은 문제점이 있다. 
1. Identifying tasks: 멀티스레드로 나눌 수 있는 영역이 있는지 판단하는 문제
	- 인과성 등을 고려하여 나눌 수 있다. 
2. Balance: 멀티스레드로 나눈다면, 어떻게 해야 균형있게 각 스레드에 작업을 분배할지 판단
3. Data splitting: 작업 뿐만 아니라 그에 해당하는 데이터 또한 그에 맞게 나누는 문제
4. Data dependency: 작업을 실행하며 각 스레드에서 실행하고 있는 작업을 동기화하는 문제
	* 하나의 데이터에 동시에 접근하면 안 되기 때문에 
5. Testing and debugging: 테스트와 디버깅의 경우, 싱글스레드의 경우보다 더 어려움

한편, **Parallelism**의 종류에는 여러 가지가 있으며, 작업에 맞게 골라서 병렬성을 구현한다. 
예를 들어, 1부터 10000까지 더하는 연산과 제곱 연산, 곱셈 연산 등 여러 연산을 수행하는 경우, 
- Data parallelism
	- 1부터 10000까지 더하는 연산에 주로 사용
	- 같은 연산을 데이터의 부분집합에 대해 반복하는 경우
	- 예시: 1부터 2000까지, 2000부터 4000까지, ... , 8000부터 10000까지 덧셈
- Task parallelism
	- 제곱 연산, 곱셈 연산 등 여러 연산을 수행하는 경우
	- 각각의 코어가 각각 다른 연산을 수행
	- A 코어는 제곱 연산, B 코어는 곱셈 연산 등등..

이를 사진으로 나타내면
![[Pasted image 20251001012734.png]]

그렇다면, 단순히 코어가 많아질수록 스피드도 같이 그에 비례해서 올라갈까? 
Amdahl's law에 의하면 정답은 '아니다'이다. 

**Amdahl's law**란, S가 시스템에서 serial(직렬적)한 부분이고, N이 코어의 개수일 때, 
$$speedup \leq \frac{1}{S + \frac{1-S}{N}}$$
위와 같이 속도의 증가가 나타난다. 

예를 들어, 시스템의 75%가 병렬화 할 수 있고, 25%가 serial할 때, 속도 증가는 다음과 같다. 
$$speedup \leq \frac{1}{0.25 + \frac{0.75}{2}} = \frac{1}{\frac{50 + 75}{200}} = \frac{200}{125} = 1.6$$
즉, Amdahl's law가 의미하는 바는 직렬적인 부분을 줄여야 멀티코어 시스템에서 Performance를 높일 수 있다. 

### Concurrency vs. Parallelism
동시성(Concurrency)과 병렬성(Parallelism)은 얼핏 들었을 때는 동일한 개념으로 생각할 수 있다.

동시성은 싱글 코어에서도 구현할 수 있으며, 시분할 시스템으로 각 스레드마다 시간을 매우 짧게 두고 실행하여 병렬 실행처럼 보이게 할 수 있다. 
![[Pasted image 20251001011105.png]]

병렬성은 동시성과 다르게 하드웨어적인 개념으로, 코어 여러개에서 여러 Thread를 동시에 실행하여 실제 병렬화를 구현하는 개념이다. 
![[Pasted image 20251001011200.png]]

---
## 중요한 단어
1. Process vs. Thread
2. Multicore Programming
3. Parallelism
4. Concurrency vs. Parallelism
5. Amdahl's law