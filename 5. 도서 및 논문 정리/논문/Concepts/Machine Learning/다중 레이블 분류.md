---
tags:
  - 머신러닝
---
# 다중 레이블 분류란?
다중 레이블 분류란, **하나의 입력 데이터가 여러 개의 정답 레이블을 동시에 가질 수 있는 분류 문제**이다.

- 단일 레이블 분류: 하나의 클래스만 선택
- 다중 레이블 분류: 여러 개의 클래스 동시 선택 가능

---

# 출력 구조 정의
입력 $x$에 대해 출력은 다음과 같은 벡터로 표현할 수 있다. 
$$y = [y_1,\ y_2,\ ...\ ,y_K]$$
- $K$: 전체 클래스 수
- $y_K \in {0,1}$

예시를 들자면 다음과 같다. 

```less
클래스: [고양이, 개, 자동차]
출력: [1, 0, 1]
```

---

# 확률 모델 정의
Sigmoid 기반 확률 모델에서, 다중 레이블에서는 각 클래스마다 독립적으로 확률을 계산한다.
$$\hat{y_k} = \sigma(z_k) = \frac{1}{1 + e^{-z_k}}$$
- $z_k$: 모델의 출력
- $\sigma()$: Sigmoid 함수

---
# 손실 함수 정의
다중 레이블 분류에서 손실 함수는 다음과 같이 정의된다. 
$$L = -\sum_{k=1}^{K}[y_k\log(\hat{y}_k) + (1 - y_k)\log(1-\hat{y}_k)]$$
- 각 클래스마다 이진 분류 문제로 처리
- 실전에서는 BCE(Binary Cross Entropy) With LogisLoss를 가장 많이 사용한다.

---

# 가장 실용적인 방식
현재 산업, 연구에서 가장 많이 사용되는 방식은 다음과 같다. 

- 노드 수: $K$
- 활성 함수: Sigmoid
- 손실 함수: BCE

---

# Python 구현 코드
```python
import torch
import torch.nn as nn
import torch.optim as optim

class MultiLabelNN(nn.Module):
    def __init__(self, input_dim, num_classes):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, num_classes)

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.fc2(x)   # sigmoid는 loss에서 처리
        return x

# 모델 생성
model = MultiLabelNN(input_dim=20, num_classes=5)

criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 예시 데이터
X = torch.randn(100, 20)
y = torch.randint(0, 2, (100, 5)).float()

# 학습
for epoch in range(50):
    optimizer.zero_grad()
    logits = model(X)
    loss = criterion(logits, y)
    loss.backward()
    optimizer.step()

    if epoch % 10 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

```

잘 살펴보면 알겠지만, 가장 실용적인 방식을 바탕으로 구현하였다.